{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of supervised and supervised model side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-03 11:59:32.893851: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-03 11:59:32.922129: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-03 11:59:32.922158: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-03 11:59:32.922800: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-03 11:59:32.927482: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-03 11:59:33.479301: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tf_dataset.tf_dataset import get_tf_dataset\n",
    "from model.models import get_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "root = '/home/ji/Dropbox/Robotics/CMSC733/Project1/Phase2/Data'\n",
    "train_path = root+\"/Train\"\n",
    "val_path = root+\"/Val\"\n",
    "test_path = root+\"/Test\"\n",
    "\n",
    "train_ds = get_tf_dataset(path=train_path,\n",
    "                    batch_size=8,\n",
    "                    mode=\"unsupervised\")\n",
    "\n",
    "val_ds = get_tf_dataset(path=val_path,\n",
    "                    batch_size=8,\n",
    "                    mode=\"unsupervised\")\n",
    "\n",
    "test_ds = get_tf_dataset(path=test_path,\n",
    "                    batch_size=8,\n",
    "                    mode=\"unsupervised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new init\n",
      "new init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-03 11:59:39.284769: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-03 11:59:39.654054: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x83f0870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7ff1681df550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load models\n",
    "model_s = get_model(mode=\"supervised\")\n",
    "model_s.load_weights(\"./chkpt_weight/checkpoint_mdl_v2_rho32\")\n",
    "\n",
    "model_us = get_model(mode=\"unsupervised\")\n",
    "model_us.load_weights(\"./chkpt_weight/checkpoint_mdl_unsupervised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def Mean_Corner_error(corners1, corners2):\n",
    "    assert corners1.shape == corners2.shape\n",
    "    distances = np.sqrt(np.sum(np.square(corners1 - corners2), axis=1))\n",
    "    mean_error = np.mean(distances)\n",
    "    return mean_error\n",
    "\n",
    "def calculate_metric(ds, nimg):\n",
    "    corner_dist_s = []\n",
    "    corner_dist_us = []\n",
    "    B = 8\n",
    "    # go through all test images\n",
    "\n",
    "    for i in tqdm(range(int(nimg/B))):\n",
    "        # retrieve a sample batch\n",
    "        sample_input, sample_output = next(iter(ds))\n",
    "        im_crop1, im_crop2, im_ori, upper_left_coord = sample_input\n",
    "        im_warp, h4pt = sample_output\n",
    "        h4pt = h4pt.numpy().reshape((-1,4,2))\n",
    "\n",
    "        h4pt_s = model_s([im_crop1,im_crop2])\n",
    "        h4pt_s = (np.round(h4pt_s.numpy())).reshape((-1,4,2))\n",
    "\n",
    "        model_out_us = model_us(sample_input)\n",
    "        im_warp_pred_us, h4pt_us = model_out_us\n",
    "        im_warp_pred_us = np.round(im_warp_pred_us.numpy()*255)\n",
    "        h4pt_us = np.round(h4pt_us.numpy()).reshape((-1,4,2))\n",
    "\n",
    "        for b in range(B):\n",
    "            corner_dist_s.append( Mean_Corner_error(np.squeeze(h4pt[b,:,:]),\n",
    "                                                np.squeeze(h4pt_s[b,:,:]))\n",
    "                                )\n",
    "            \n",
    "            corner_dist_us.append( Mean_Corner_error(np.squeeze(h4pt[b,:,:]),\n",
    "                                                np.squeeze(h4pt_us[b,:,:]))\n",
    "                                )\n",
    "        \n",
    "    corner_dist_s = np.array(corner_dist_s)\n",
    "    corner_dist_us = np.array(corner_dist_us)\n",
    "\n",
    "    return corner_dist_s, corner_dist_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_s_train, cd_us_train = calculate_metric(train_ds, nimg=5000)\n",
    "cd_s_val, cd_us_val = calculate_metric(val_ds, nimg=1000)\n",
    "cd_s_test, cd_us_test = calculate_metric(test_ds, nimg=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "\tsupervised model error: mean 5.160, std 2.486\n",
      "\tunsupervised model error: mean 16.018, std 5.756\n",
      "Validation set:\n",
      "\tsupervised model error: mean 5.149, std 2.574\n",
      "\tunsupervised model error: mean 16.069, std 5.743\n",
      "Test set:\n",
      "\tsupervised model error: mean 5.159, std 2.356\n",
      "\tunsupervised model error: mean 15.834, std 5.214\n"
     ]
    }
   ],
   "source": [
    "def print_result(corner_dist_s, corner_dist_us):\n",
    "    print( (f\"\\tsupervised model error: mean {np.mean(corner_dist_s):.3f}, \"\n",
    "            f\"std {np.std(corner_dist_s):.3f}\")\n",
    "        )\n",
    "    print( (f\"\\tunsupervised model error: mean {np.mean(corner_dist_us):.3f}, \"\n",
    "            f\"std {np.std(corner_dist_us):.3f}\")\n",
    "     )\n",
    "\n",
    "print(\"Training set:\")\n",
    "print_result(cd_s_train, cd_us_train)\n",
    "\n",
    "print(\"Validation set:\")\n",
    "print_result(cd_s_val, cd_us_val)\n",
    "\n",
    "print(\"Test set:\")\n",
    "print_result(cd_s_test, cd_us_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
